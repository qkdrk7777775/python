{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:18:26.735098Z",
     "iopub.status.busy": "2020-11-27T04:18:26.734719Z",
     "iopub.status.idle": "2020-11-27T04:18:28.487587Z",
     "shell.execute_reply": "2020-11-27T04:18:28.487145Z",
     "shell.execute_reply.started": "2020-11-27T04:18:26.735045Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:15.852607Z",
     "iopub.status.busy": "2020-11-26T16:29:15.852220Z",
     "iopub.status.idle": "2020-11-26T16:29:15.856350Z",
     "shell.execute_reply": "2020-11-26T16:29:15.855827Z",
     "shell.execute_reply.started": "2020-11-26T16:29:15.852583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:18:28.706049Z",
     "iopub.status.busy": "2020-11-27T04:18:28.705916Z",
     "iopub.status.idle": "2020-11-27T04:18:29.070302Z",
     "shell.execute_reply": "2020-11-27T04:18:29.069724Z",
     "shell.execute_reply.started": "2020-11-27T04:18:28.706031Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 채널 차원을 추가합니다.\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:19.541127Z",
     "iopub.status.busy": "2020-11-26T16:29:19.540778Z",
     "iopub.status.idle": "2020-11-26T16:29:19.901354Z",
     "shell.execute_reply": "2020-11-26T16:29:19.900761Z",
     "shell.execute_reply.started": "2020-11-26T16:29:19.541102Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:20.486857Z",
     "iopub.status.busy": "2020-11-26T16:29:20.486617Z",
     "iopub.status.idle": "2020-11-26T16:29:20.512174Z",
     "shell.execute_reply": "2020-11-26T16:29:20.511752Z",
     "shell.execute_reply.started": "2020-11-26T16:29:20.486831Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:21.095107Z",
     "iopub.status.busy": "2020-11-26T16:29:21.094845Z",
     "iopub.status.idle": "2020-11-26T16:29:21.099927Z",
     "shell.execute_reply": "2020-11-26T16:29:21.098771Z",
     "shell.execute_reply.started": "2020-11-26T16:29:21.095071Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:21.696560Z",
     "iopub.status.busy": "2020-11-26T16:29:21.695732Z",
     "iopub.status.idle": "2020-11-26T16:29:22.104352Z",
     "shell.execute_reply": "2020-11-26T16:29:22.103916Z",
     "shell.execute_reply.started": "2020-11-26T16:29:21.696461Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:24.486503Z",
     "iopub.status.busy": "2020-11-26T16:29:24.486262Z",
     "iopub.status.idle": "2020-11-26T16:29:24.494958Z",
     "shell.execute_reply": "2020-11-26T16:29:24.494374Z",
     "shell.execute_reply.started": "2020-11-26T16:29:24.486474Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:25.484007Z",
     "iopub.status.busy": "2020-11-26T16:29:25.483762Z",
     "iopub.status.idle": "2020-11-26T16:29:25.488316Z",
     "shell.execute_reply": "2020-11-26T16:29:25.487728Z",
     "shell.execute_reply.started": "2020-11-26T16:29:25.483981Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  predictions = model(images)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:29:26.719000Z",
     "iopub.status.busy": "2020-11-26T16:29:26.717870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "에포크: 1, 손실: 0.13440388441085815, 정확도: 95.98833465576172, 테스트 손실: 0.06783552467823029, 테스트 정확도: 97.6199951171875\n",
      "에포크: 2, 손실: 0.08856844156980515, 정확도: 97.33499908447266, 테스트 손실: 0.06047859415411949, 테스트 정확도: 97.88500213623047\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  template = '에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/examples/vision/conv_lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(\n",
    "            shape=(None, 40, 40, 1)\n",
    "        ),  # Variable-length sequence of 40x40x1 frames\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=1, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "        ),\n",
    "#         layers.BatchNormalization(),\n",
    "#         layers.ConvLSTM2D(\n",
    "#             filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "#         ),\n",
    "#         layers.BatchNormalization(),\n",
    "#         layers.ConvLSTM2D(\n",
    "#             filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
    "#         ),\n",
    "#         layers.BatchNormalization(),\n",
    "#         layers.Conv3D(\n",
    "#             filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    "#         ),\n",
    "    ]\n",
    ")\n",
    "seq.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-11-27T04:51:57.790798Z",
     "iopub.status.busy": "2020-11-27T04:51:57.790511Z",
     "iopub.status.idle": "2020-11-27T04:51:57.803268Z",
     "shell.execute_reply": "2020-11-27T04:51:57.802557Z",
     "shell.execute_reply.started": "2020-11-27T04:51:57.790769Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_2',\n",
       " 'layers': [{'class_name': 'ConvLSTM2D',\n",
       "   'config': {'name': 'conv_lst_m2d_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': True,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': False,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'filters': 40,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'tanh',\n",
       "    'recurrent_activation': 'hard_sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.0,\n",
       "    'recurrent_dropout': 0.0,\n",
       "    'batch_input_shape': (None, None, 40, 40, 1)}},\n",
       "  {'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': ListWrapper([4]),\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None}},\n",
       "  {'class_name': 'ConvLSTM2D',\n",
       "   'config': {'name': 'conv_lst_m2d_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': True,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': False,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'filters': 1,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'tanh',\n",
       "    'recurrent_activation': 'hard_sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.0,\n",
       "    'recurrent_dropout': 0.0}}],\n",
       " 'build_input_shape': TensorShape([None, None, 40, 40, 1])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:02.786516Z",
     "iopub.status.busy": "2020-11-27T04:52:02.785988Z",
     "iopub.status.idle": "2020-11-27T04:52:02.794753Z",
     "shell.execute_reply": "2020-11-27T04:52:02.794049Z",
     "shell.execute_reply.started": "2020-11-27T04:52:02.786456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_5 (ConvLSTM2D)  (None, None, 40, 40, 40)  59200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 40, 40, 40)  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_6 (ConvLSTM2D)  (None, None, 40, 40, 1)   1480      \n",
      "=================================================================\n",
      "Total params: 60,840\n",
      "Trainable params: 60,760\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[\n",
    "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
    "                ] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the model to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1) ** np.random.randint(0, 2)\n",
    "                    noisy_movies[\n",
    "                        i,\n",
    "                        t,\n",
    "                        x_shift - w - 1 : x_shift + w + 1,\n",
    "                        y_shift - w - 1 : y_shift + w + 1,\n",
    "                        0,\n",
    "                    ] += (noise_f * 0.1)\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[\n",
    "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
    "                ] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "epochs = 1  # In practice, you would need hundreds of epochs.\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "seq.fit(\n",
    "    noisy_movies[:1000],\n",
    "    shifted_movies[:1000],\n",
    "    batch_size=10,\n",
    "    epochs=epochs,\n",
    "    verbose=2,\n",
    "    validation_split=0.1,callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:24.790978Z",
     "iopub.status.busy": "2020-11-27T04:52:24.790692Z",
     "iopub.status.idle": "2020-11-27T04:52:27.414603Z",
     "shell.execute_reply": "2020-11-27T04:52:27.413860Z",
     "shell.execute_reply.started": "2020-11-27T04:52:24.790952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 40, 40, 1)\n",
      "(8, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "movie_index = 1004\n",
    "test_movie = noisy_movies[movie_index]\n",
    "\n",
    "# Start from first 7 frames\n",
    "track = test_movie[:7, ::, ::, ::]\n",
    "print(track.shape)\n",
    "# Predict 16 frames\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "    print(track.shape)\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:27.821353Z",
     "iopub.status.busy": "2020-11-27T04:52:27.820833Z",
     "iopub.status.idle": "2020-11-27T04:52:27.826757Z",
     "shell.execute_reply": "2020-11-27T04:52:27.826292Z",
     "shell.execute_reply.started": "2020-11-27T04:52:27.821294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 40, 40, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_movie[np.newaxis,:7, ::, ::, ::].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:34.834699Z",
     "iopub.status.busy": "2020-11-27T04:52:34.834329Z",
     "iopub.status.idle": "2020-11-27T04:52:34.839685Z",
     "shell.execute_reply": "2020-11-27T04:52:34.839073Z",
     "shell.execute_reply.started": "2020-11-27T04:52:34.834660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 40, 40, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:35.783371Z",
     "iopub.status.busy": "2020-11-27T04:52:35.783008Z",
     "iopub.status.idle": "2020-11-27T04:52:35.789721Z",
     "shell.execute_reply": "2020-11-27T04:52:35.788949Z",
     "shell.execute_reply.started": "2020-11-27T04:52:35.783328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 40, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pos[::, -1, ::, ::, ::].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:36.786598Z",
     "iopub.status.busy": "2020-11-27T04:52:36.786208Z",
     "iopub.status.idle": "2020-11-27T04:52:36.792589Z",
     "shell.execute_reply": "2020-11-27T04:52:36.791744Z",
     "shell.execute_reply.started": "2020-11-27T04:52:36.786554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 40, 40, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:37.786093Z",
     "iopub.status.busy": "2020-11-27T04:52:37.785708Z",
     "iopub.status.idle": "2020-11-27T04:52:37.792746Z",
     "shell.execute_reply": "2020-11-27T04:52:37.791911Z",
     "shell.execute_reply.started": "2020-11-27T04:52:37.786049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 40, 40, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_movie[:7, ::, ::, ::].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-27T04:52:42.793277Z",
     "iopub.status.busy": "2020-11-27T04:52:42.793088Z",
     "iopub.status.idle": "2020-11-27T04:52:42.797792Z",
     "shell.execute_reply": "2020-11-27T04:52:42.797217Z",
     "shell.execute_reply.started": "2020-11-27T04:52:42.793252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 40, 40, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((track, new), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
